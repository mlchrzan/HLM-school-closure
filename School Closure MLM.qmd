---
title: "School Closure MLM"
author: "mlc"
format: html
editor: visual
---

# Setup

```{r libraries, message=FALSE}
library(tidyverse)
library(lme4)
library(lmerTest)
library(performance)
library(lattice)
library(here)
library(janitor) #for clean_names()
library(DescTools) #for Winsorize()
library(GGally) #for correlation matrix
library(corrplot) #for correlation matrix
library(plotly)
library(naniar)
library(caret) #for up and down sampling
```

```{r load-data, message=FALSE}
closure <- read_csv("school_district_theil_index.csv")
district_states <- read_csv("district_state_info.csv", skip = 6)
district_states <- clean_names(district_states)

district_states <- district_states |> 
  rename(agency_id = starts_with("agency_id"), 
         dist_state_name = starts_with('state_name'),
         dist_state_abbr = starts_with('state_abbr')) |> 
  mutate(agency_id = as.numeric(agency_id), 
         dist_state_abbr = as.factor(dist_state_abbr), 
         dist_state_name = as.factor(dist_state_name))

closure <- left_join(closure, 
                     district_states, 
                     by = join_by(agency_id))
rm(district_states)

closure <- closure |> 
  dplyr::select(agency_id, 
                school_id, 
                year, 
                school_name, 
                dist_state_name, 
                dist_state_abbr, 
                everything())
```

```{r initial-set-up}
closure <- closure |> 
  mutate(school_level = if_else(school_level == 5 | school_level ==6, 4, school_level)) 

#Recreate location type from dummy variables, including NA's where appropriate
location_known <- closure |> 
  pivot_longer(cols = c(urban, suburban, rural), 
               names_to = "location_type") |> 
  mutate(location_type = if_else(value == 0, NA, location_type)) |>
  filter(value == 1) |>
  dplyr::select(-value)
  
rows_without_location <- closure |> 
  pivot_longer(cols = c(urban, suburban, rural), 
               names_to = "location_type") |> 
  mutate(location_type = if_else(value == 0, NA, location_type)) |>
  distinct() |> 
  filter(value == 0) |>
  dplyr::select(-value) 

location_unknown <- anti_join(rows_without_location, location_known, 
                              by = join_by(school_id, year))

closure <- bind_rows(location_known, location_unknown) 
rm(location_known, location_unknown, rows_without_location)


#Remove persisting rows for schools after they close
closure <- closure |> 
  #Find year school closed
  group_by(school_id, year) |> 
  filter(closed == 1) |> 
  summarize(year_closed = year, 
            .groups = 'keep') |> 
  ungroup() |> 
  dplyr::select(-year) |> 
  #Filter to only include years less than or equal to that year for each school
  right_join(closure) |> 
  mutate(year_closed = if_else(is.na(year_closed), Year(Today()), year_closed)) |> 
  filter(year <= year_closed) |> 
  dplyr::select(year_closed, agency_id, school_id, school_name, year, closed, everything()) |> 
  dplyr::select(-year_closed, -agency_name)


#Create factors
closure <- closure |> 
  mutate(school_id = factor(school_id, levels = unique(school_id)), 
         agency_id = factor(agency_id, levels = unique(agency_id)), 
         #year = factor(year, levels = unique(year)),
         closed = factor(closed, levels = unique(closed)),
         school_level = factor(school_level, levels = unique(school_level)), 
         charter = factor(charter, levels = unique(charter)), 
         magnet = factor(magnet, levels = unique(magnet)), 
         title1 = factor(title1, levels = unique(title1)), 
         location_type = factor(location_type, levels = unique(location_type)))
```

```{r cleaning-variables}
#Correct Location Types

#Create Mode function to find the most common value that is not NA
Mode <- function(x, na.rm = FALSE) {
  if(na.rm){
    x = x[!is.na(x)]
  }

  ux <- unique(x)
  return(ux[which.max(tabulate(match(x, ux)))])
}

closure <- closure |> 
  group_by(school_id) |> 
  mutate(most_common_location = Mode(location_type, na.rm = TRUE)) |> 
  mutate(location_type = most_common_location) |> 
  ungroup() |> 
  dplyr::select(-most_common_location)

  

#Correct Percentages/Ratios
  #maxval's chosen based on distributions
closure$st_ratio <- Winsorize(closure$st_ratio, 
                              minval = 1,
                              maxval = 51, 
                              na.rm = TRUE)

closure$dist_st_ratio <- Winsorize(closure$dist_st_ratio, 
                                   minval = 1,
                                   maxval = 33,
                                   na.rm = TRUE)

  #all percentages higher than 100 capped to 100
closure <- closure |>  
  mutate(across((starts_with("dist_pct")), ~if_else(. > 1, 1, .)), 
         pct_frpl = if_else(pct_frpl > 1, 1, pct_frpl))


#Fix districts indicating no students enrollled
closure <- closure |> 
  group_by(agency_id, year) |> 
  mutate(dist_tot_students = if_else(dist_tot_students == 0, 
                                     sum(tot_students), 
                                     dist_tot_students), 
         dist_tot_students = if_else(dist_tot_students == 0, 
                                    NA, 
                                    dist_tot_students), 
         tot_students = if_else(tot_students == 0, 
                                    NA, 
                                    tot_students)) |> 
  ungroup() 



#Title1 Categories (Can I get a clean yes/no)
```

```{r creating-variables}
#Enrollment Trends
closure <- closure |> 
  group_by(school_id) |> 
  mutate(one_yr_enroll_schl = tot_students - dplyr::lag(tot_students),
         one_yr_enroll_dist = dist_tot_students - dplyr::lag(dist_tot_students),
         five_yr_enroll_schl = tot_students - dplyr::lag(tot_students, n = 5),
         five_yr_enroll_dist = dist_tot_students - dplyr::lag(dist_tot_students, n = 5), 
         three_yr_enroll_schl = tot_students - dplyr::lag(tot_students, n = 3), 
         three_yr_enroll_dist = dist_tot_students - dplyr::lag(dist_tot_students, n = 3)) |>
  ungroup()


#What percent of of District Enrollment is at a given school? 
closure <- closure |> 
  mutate(pct_dist_enroll = tot_students/dist_tot_students)

#Is the school more diverse than the district? 
closure <- closure |> 
  mutate(school_more_diverse = if_else(sch_theil < dist_theil, "Yes", "No"))

#Calculate the number of schools a district has within a given year
closure <- closure |> 
  group_by(agency_id, year) |> 
  mutate(dist_num_schools = n_distinct(school_id)) |> 
  ungroup()
```

```{r cleaning-dist-pct-enroll}
#Fixing dist_tot_student totals for schools and years where the pct was over 100 (dist count wasn't 0, but was still too low, single digit counts)

closure <- closure |> 
  group_by(agency_id, year) |> 
  mutate(dist_tot_students = if_else(pct_dist_enroll > 100, 
                                     sum(tot_students), 
                                     dist_tot_students), 
         pct_dist_enroll = if_else(pct_dist_enroll > 100, 
                                   tot_students/dist_tot_students, 
                                   pct_dist_enroll)) |> 
  ungroup()  

summary(closure$pct_dist_enroll)
```

```{r filter-CA}
closure_CA <- closure |> 
  filter(dist_state_abbr == "CA") 
```

```{r standardize}
closure_CA <- closure_CA |> 
  select(agency_id, school_id, school_level,
         year, closed, dist_state_abbr, 
         location_type,
         pct_dist_enroll, 
         school_level, 
         st_ratio, 
         school_more_diverse,
         three_yr_enroll_dist, 
         dist_st_ratio, 
         dist_per_pupil_expend, 
         dist_num_schools) |> 
  mutate(across(where(is.numeric) & !year, scale),
         across(where(is.numeric) & !year, as.vector), 
         year = year - min(year)) |> 
  na.omit()

closure_CA

#SCHOOL LEVEL
#pct_dist_enroll
#st_ratio
#school_level
#school_more_diverse ???, maybe we try this with schl_pct_blk and dist_pct_blk at level 2
#five_yr_enroll_schl 

#DISTRICT LEVEL
#dist_st_ratio
#dist_per_pupil_expend
#dist_num_schools
```

```{r cleaning-year-factor}
# closure_CA <- closure_CA |> 
#   filter(year != 2000 & year != 2001 & year != 2002)
# 
# closure_CA <- closure_CA |> 
#   mutate(year = factor(year, levels = c(2003:2017)))
```

# Check Data

```{r check-level}
closure_CA |>
  group_by(agency_id) |>
  summarize(across(where(is.numeric), ~ sd(., na.rm = TRUE)))

#All numerical variables are time-varying
```

```{r data-characteristics}
#Number of Schools
n_distinct(closure_CA$school_id)

#Number of Districts
n_distinct(closure_CA$agency_id)

#Number of Schools Over Time
closure_CA |> 
  group_by(year) |> 
  summarize(num_schools = n()) |> 
  ungroup()

#Number of Districts Over Time
closure_CA |> 
  group_by(year) |> 
  summarize(num_dists = n_distinct(agency_id)) |> 
  ungroup()

#Prior of closure
summary(closure_CA$closed)
closure_CA$closed==1

```

```{r clean-first-three-years}
#Clean out first three years (due to lags earlier)
closure_CA <- closure_CA |> 
  filter(year > 2) |> 
  mutate(year = year - min(year))
```

# 5 Hypothesis

## Examine Linearity and Outliers

```{r check-linearity-plot-attitudes-over-time}
closure_CA |> 
  group_by(year) |> 
  summarize(num_closed = sum(as.numeric(closed == 1))) |> 
  ungroup() |> 
  ggplot(aes(x = as.numeric(year),
             y = num_closed)) +
  geom_point() +
  geom_smooth(method = "loess", se = F) + # flexible model
  geom_smooth(method = "lm", se = F, colour = "red")
```

```{r test-time-options}
mlfit <- lm(closed == 1 ~ as.numeric(year), 
            data = closure_CA)
mqfit <- lm(closed == 1 ~ poly(as.numeric(year), 2), # quadratic effect
            data = closure_CA)
mdfit <- lm(closed == 1 ~ closure_CA$year, 
            data = closure_CA) # time dummies

summary(mlfit)
summary(mqfit)
summary(mdfit)
```

```{r test-time-models}
anova(mqfit, mlfit) 
anova(mdfit, mlfit) 
```

We'll use the quadratic effect fit

\>\>\> ARE WE SUPPOSED TO TEST EACH VARIABLE??

## Models?

```{r make-testing-samples}
set.seed(1234)
down_sample <- closure_CA |> 
  downSample(y = closure_CA$closed)

down_sample <- down_sample |> droplevels()
```

```{r view-samples}
# sample
# down_sample
# up_sample
# mod_down_samp

# Check Sample Proportions
sample |> 
  group_by(closed) |> 
  summarize(n = n()) |> 
  mutate(prop = n / sum(n)) |> 
  ungroup()

down_sample |> 
  group_by(closed) |> 
  summarize(n = n()) |> 
  mutate(prop = n / sum(n)) |> 
  ungroup()

up_sample |> 
  group_by(closed) |> 
  summarize(n = n()) |> 
  mutate(prop = n / sum(n)) |> 
  ungroup()

mod_down_samp |> 
  group_by(closed) |> 
  summarize(n = n()) |> 
  mutate(prop = n / sum(n)) |> 
  ungroup()
```

```{r down-sample}
m0_d <- glm(closed ~ year,  
          data = down_sample,
          family = binomial(link = "logit"))


m1_d <- glmer(closed ~ year + (1 | school_id) ,  
            data = down_sample,
            family = binomial(link = "logit"))

summary(m0_d)
summary(m1_d)
```

```{r up-sample}
m0 <- glm(closed ~ year,  
          data = up_sample,
          family = binomial(link = "logit"))



m1 <- glmer(closed ~ year + (1 | school_id) ,  
            data = up_sample,
            family = binomial(link = "logit"))

summary(m0)
summary(m1)

#start with regular glm and then input the values in a MLGLM as starting values
#try to find a way to manually downsample the data
```

```{r modified-down-sample}
m0_mod_d <- glm(closed ~ year,  
          data = mod_down_samp,
          family = binomial(link = "logit"))



m1_mod_d <- glmer(closed ~ year + (1 | school_id) ,  
            data = mod_down_samp,
            family = binomial(link = "logit"))

summary(m0_mod_d)
summary(m1_mod_d)
```

```{r}
closure |> 
  group_by(closed, dist_state_abbr) |> 
  summarize(n = n()) |> 
  mutate(prop = n / sum(n)) |> 
  ungroup() |> 
  filter(closed == 1) |> 
  arrange(desc(prop))
```

# OLD AND WRONG

## 5 Hypothesis

```{r mean-center}
# vars <- closure_CA  |>  
#   select(where(is.numeric))  |>  
#   names() 
# vars <- setNames(vars, str_c(vars, "_c")) 
# #vars
# 
# closure_CA <- closure_CA |>
#   mutate(across(all_of(vars), ~ . - mean(., na.rm = TRUE))) 
```

```{r check-mean-center}
# closure_CA |>
#   select(ends_with("_c")) |>
#   summary()
```

## Step 1

```{r}
m1 <- glm(closed ~ 1 ,
         data = closure_CA, 
         family = 'binomial')
summary(m1)
```

```{r}
logLik(m1) #deviance
```

## Step 2

```{r random-intercept}
m2 <- glmer(closed ~ (1 | school_id),  
            data = closure_CA, 
            family = 'binomial') 

summary(m2)
```

```{r icc}
icc(m2)
```

```{r anova-m2-m1}
(2* logLik(m2)) - (2* logLik(m1))

anova(m2,m1)
```

## Step 3: A model with a level 1 predictor

```{r variables}
#SCHOOL LEVEL
#pct_dist_enroll
#st_ratio
#school_level
#school_more_diverse ???

#DISTRICT LEVEL
#dist_five_year_enroll 
#dist_st_ratio
#dist_per_pupil_expend
#num_schools
```

```{r}
closure_CA |> 
  ggplot(aes(x = year)) + geom_histogram()
```

```{r level-1-predictors}
m3 <- glmer(closed ~ 
              pct_dist_enroll 
            #+ st_ratio 
            #+ school_level 
            + (1 | school_id),  
            data = closure_CA, 
            family = "binomial") 

summary(m3)
```

```{r model-comparison-2}
anova(m3, m2)
#(2* logLik(m2)) - (2* logLik(m1))
#(2* logLik(m3)) - (2* logLik(m2))

#Not nested models! There was some listwise deletion from one of the covariates missing variables

#Take out all the missing values after selecting the variables, do some naniar analysis on the missing data 

# logLik(m1)
# logLik(m2)
# logLik(m3)
```

## Step 4 a model with level 2 predictors

```{r level-2-predictors}
#DISTRICT LEVEL
#dist_five_year_enroll 
#dist_st_ratio
#dist_per_pupil_expend
#num_schools

m4 <- glmer(closed ~ pct_di5st_enroll + st_ratio + school_level 
            + three_yr_enroll_dist + dist_st_ratio + dist_per_pupil_expend 
            + dist_num_schools + (1 | agency_id),  
            data = closure_CA, 
            family = "binomial") 

summary(m4)
```
